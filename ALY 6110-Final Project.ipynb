{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New York Police Department Crime Records Analysis \n",
    "\n",
    "### Exploratory Data Analysis\n",
    "\n",
    "We import the dataset to clean and perform our exploratory data analysis - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the dataset containing 5 million records\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "nRowsRead = 5012956\n",
    "data = pd.read_csv('C:/Users/SwetaMankala/OneDrive - Northeastern University/Data Management and Big Data/NYPD_Arrests_Data__Historic_.csv', delimiter=',', nrows = nRowsRead, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARREST_KEY</th>\n",
       "      <th>ARREST_DATE</th>\n",
       "      <th>PD_CD</th>\n",
       "      <th>PD_DESC</th>\n",
       "      <th>KY_CD</th>\n",
       "      <th>OFNS_DESC</th>\n",
       "      <th>LAW_CODE</th>\n",
       "      <th>LAW_CAT_CD</th>\n",
       "      <th>ARREST_BORO</th>\n",
       "      <th>ARREST_PRECINCT</th>\n",
       "      <th>JURISDICTION_CODE</th>\n",
       "      <th>AGE_GROUP</th>\n",
       "      <th>PERP_SEX</th>\n",
       "      <th>PERP_RACE</th>\n",
       "      <th>X_COORD_CD</th>\n",
       "      <th>Y_COORD_CD</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Lon_Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>144026181</td>\n",
       "      <td>06/26/2015</td>\n",
       "      <td>639.0</td>\n",
       "      <td>AGGRAVATED HARASSMENT 2</td>\n",
       "      <td>361.0</td>\n",
       "      <td>OFF. AGNST PUB ORD SENSBLTY &amp; RGHTS TO PRIV</td>\n",
       "      <td>PL 2403002</td>\n",
       "      <td>M</td>\n",
       "      <td>Q</td>\n",
       "      <td>102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45-64</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>1031076.0</td>\n",
       "      <td>193779.0</td>\n",
       "      <td>40.698440</td>\n",
       "      <td>-73.831130</td>\n",
       "      <td>POINT (-73.83112953899997 40.69843969400005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>144507595</td>\n",
       "      <td>07/14/2015</td>\n",
       "      <td>969.0</td>\n",
       "      <td>TRAFFIC,UNCLASSIFIED INFRACTION</td>\n",
       "      <td>881.0</td>\n",
       "      <td>OTHER TRAFFIC INFRACTION</td>\n",
       "      <td>VTL051101A</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25-44</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>984791.0</td>\n",
       "      <td>209846.0</td>\n",
       "      <td>40.742664</td>\n",
       "      <td>-73.998049</td>\n",
       "      <td>POINT (-73.99804910799998 40.74266360800004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>144565062</td>\n",
       "      <td>07/16/2015</td>\n",
       "      <td>101.0</td>\n",
       "      <td>ASSAULT 3</td>\n",
       "      <td>344.0</td>\n",
       "      <td>ASSAULT 3 &amp; RELATED OFFENSES</td>\n",
       "      <td>PL 1200001</td>\n",
       "      <td>M</td>\n",
       "      <td>K</td>\n",
       "      <td>90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>994026.0</td>\n",
       "      <td>195548.0</td>\n",
       "      <td>40.703414</td>\n",
       "      <td>-73.964743</td>\n",
       "      <td>POINT (-73.96474295699994 40.70341366900004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>144500188</td>\n",
       "      <td>07/14/2015</td>\n",
       "      <td>879.0</td>\n",
       "      <td>ADM.CODE,UNCLASSIFIED VIOLATION</td>\n",
       "      <td>675.0</td>\n",
       "      <td>ADMINISTRATIVE CODE</td>\n",
       "      <td>AC 010125B</td>\n",
       "      <td>V</td>\n",
       "      <td>Q</td>\n",
       "      <td>103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25-44</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>1037132.0</td>\n",
       "      <td>196129.0</td>\n",
       "      <td>40.704856</td>\n",
       "      <td>-73.809271</td>\n",
       "      <td>POINT (-73.809270971 40.70485576300007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>144216044</td>\n",
       "      <td>07/03/2015</td>\n",
       "      <td>478.0</td>\n",
       "      <td>THEFT OF SERVICES, UNCLASSIFIED</td>\n",
       "      <td>343.0</td>\n",
       "      <td>OTHER OFFENSES RELATED TO THEFT</td>\n",
       "      <td>PL 1651503</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>984602.0</td>\n",
       "      <td>210686.0</td>\n",
       "      <td>40.744969</td>\n",
       "      <td>-73.998731</td>\n",
       "      <td>POINT (-73.99873112099993 40.74496920800005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>144925030</td>\n",
       "      <td>07/30/2015</td>\n",
       "      <td>339.0</td>\n",
       "      <td>LARCENY,PETIT FROM OPEN AREAS,UNCLASSIFIED</td>\n",
       "      <td>341.0</td>\n",
       "      <td>PETIT LARCENY</td>\n",
       "      <td>PL 1552500</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1030990.0</td>\n",
       "      <td>255310.0</td>\n",
       "      <td>40.867326</td>\n",
       "      <td>-73.831012</td>\n",
       "      <td>POINT (-73.83101160699994 40.86732605200007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>143984249</td>\n",
       "      <td>06/25/2015</td>\n",
       "      <td>849.0</td>\n",
       "      <td>NY STATE LAWS,UNCLASSIFIED VIOLATION</td>\n",
       "      <td>677.0</td>\n",
       "      <td>OTHER STATE LAWS</td>\n",
       "      <td>LOC000000V</td>\n",
       "      <td>V</td>\n",
       "      <td>K</td>\n",
       "      <td>78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>991330.0</td>\n",
       "      <td>187303.0</td>\n",
       "      <td>40.680786</td>\n",
       "      <td>-73.974475</td>\n",
       "      <td>POINT (-73.97447511599997 40.68078561300007)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>144541169</td>\n",
       "      <td>07/15/2015</td>\n",
       "      <td>203.0</td>\n",
       "      <td>TRESPASS 3, CRIMINAL</td>\n",
       "      <td>352.0</td>\n",
       "      <td>CRIMINAL TRESPASS</td>\n",
       "      <td>PL 1401000</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25-44</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1028017.0</td>\n",
       "      <td>262766.0</td>\n",
       "      <td>40.887806</td>\n",
       "      <td>-73.841712</td>\n",
       "      <td>POINT (-73.84171183999997 40.88780567700008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>144662834</td>\n",
       "      <td>07/20/2015</td>\n",
       "      <td>511.0</td>\n",
       "      <td>CONTROLLED SUBSTANCE, POSSESSION 7</td>\n",
       "      <td>235.0</td>\n",
       "      <td>DANGEROUS DRUGS</td>\n",
       "      <td>PL 2200300</td>\n",
       "      <td>M</td>\n",
       "      <td>B</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18-24</td>\n",
       "      <td>F</td>\n",
       "      <td>BLACK HISPANIC</td>\n",
       "      <td>1012786.0</td>\n",
       "      <td>254319.0</td>\n",
       "      <td>40.864684</td>\n",
       "      <td>-73.896833</td>\n",
       "      <td>POINT (-73.89683284499995 40.86468367600002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>144534233</td>\n",
       "      <td>07/15/2015</td>\n",
       "      <td>511.0</td>\n",
       "      <td>CONTROLLED SUBSTANCE, POSSESSION 7</td>\n",
       "      <td>235.0</td>\n",
       "      <td>DANGEROUS DRUGS</td>\n",
       "      <td>PL 2200300</td>\n",
       "      <td>M</td>\n",
       "      <td>Q</td>\n",
       "      <td>115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25-44</td>\n",
       "      <td>M</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>1018162.0</td>\n",
       "      <td>214190.0</td>\n",
       "      <td>40.754522</td>\n",
       "      <td>-73.877599</td>\n",
       "      <td>POINT (-73.87759928199995 40.754521787000044)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARREST_KEY ARREST_DATE  PD_CD                                     PD_DESC  \\\n",
       "0   144026181  06/26/2015  639.0                     AGGRAVATED HARASSMENT 2   \n",
       "1   144507595  07/14/2015  969.0             TRAFFIC,UNCLASSIFIED INFRACTION   \n",
       "2   144565062  07/16/2015  101.0                                   ASSAULT 3   \n",
       "3   144500188  07/14/2015  879.0             ADM.CODE,UNCLASSIFIED VIOLATION   \n",
       "4   144216044  07/03/2015  478.0             THEFT OF SERVICES, UNCLASSIFIED   \n",
       "5   144925030  07/30/2015  339.0  LARCENY,PETIT FROM OPEN AREAS,UNCLASSIFIED   \n",
       "6   143984249  06/25/2015  849.0        NY STATE LAWS,UNCLASSIFIED VIOLATION   \n",
       "7   144541169  07/15/2015  203.0                        TRESPASS 3, CRIMINAL   \n",
       "8   144662834  07/20/2015  511.0          CONTROLLED SUBSTANCE, POSSESSION 7   \n",
       "9   144534233  07/15/2015  511.0          CONTROLLED SUBSTANCE, POSSESSION 7   \n",
       "\n",
       "   KY_CD                                    OFNS_DESC    LAW_CODE LAW_CAT_CD  \\\n",
       "0  361.0  OFF. AGNST PUB ORD SENSBLTY & RGHTS TO PRIV  PL 2403002          M   \n",
       "1  881.0                     OTHER TRAFFIC INFRACTION  VTL051101A          M   \n",
       "2  344.0                 ASSAULT 3 & RELATED OFFENSES  PL 1200001          M   \n",
       "3  675.0                          ADMINISTRATIVE CODE  AC 010125B          V   \n",
       "4  343.0              OTHER OFFENSES RELATED TO THEFT  PL 1651503          M   \n",
       "5  341.0                                PETIT LARCENY  PL 1552500          M   \n",
       "6  677.0                             OTHER STATE LAWS  LOC000000V          V   \n",
       "7  352.0                            CRIMINAL TRESPASS  PL 1401000          M   \n",
       "8  235.0                              DANGEROUS DRUGS  PL 2200300          M   \n",
       "9  235.0                              DANGEROUS DRUGS  PL 2200300          M   \n",
       "\n",
       "  ARREST_BORO  ARREST_PRECINCT  JURISDICTION_CODE AGE_GROUP PERP_SEX  \\\n",
       "0           Q              102                0.0     45-64        M   \n",
       "1           M               10                3.0     25-44        M   \n",
       "2           K               90                0.0     18-24        F   \n",
       "3           Q              103                0.0     25-44        M   \n",
       "4           M               10                1.0     18-24        M   \n",
       "5           B               45                0.0     18-24        M   \n",
       "6           K               78                1.0     18-24        M   \n",
       "7           B               47                2.0     25-44        M   \n",
       "8           B               52                0.0     18-24        F   \n",
       "9           Q              115                0.0     25-44        M   \n",
       "\n",
       "        PERP_RACE  X_COORD_CD  Y_COORD_CD   Latitude  Longitude  \\\n",
       "0  WHITE HISPANIC   1031076.0    193779.0  40.698440 -73.831130   \n",
       "1  WHITE HISPANIC    984791.0    209846.0  40.742664 -73.998049   \n",
       "2  WHITE HISPANIC    994026.0    195548.0  40.703414 -73.964743   \n",
       "3  WHITE HISPANIC   1037132.0    196129.0  40.704856 -73.809271   \n",
       "4  WHITE HISPANIC    984602.0    210686.0  40.744969 -73.998731   \n",
       "5           BLACK   1030990.0    255310.0  40.867326 -73.831012   \n",
       "6           BLACK    991330.0    187303.0  40.680786 -73.974475   \n",
       "7           BLACK   1028017.0    262766.0  40.887806 -73.841712   \n",
       "8  BLACK HISPANIC   1012786.0    254319.0  40.864684 -73.896833   \n",
       "9           BLACK   1018162.0    214190.0  40.754522 -73.877599   \n",
       "\n",
       "                                         Lon_Lat  \n",
       "0   POINT (-73.83112953899997 40.69843969400005)  \n",
       "1   POINT (-73.99804910799998 40.74266360800004)  \n",
       "2   POINT (-73.96474295699994 40.70341366900004)  \n",
       "3        POINT (-73.809270971 40.70485576300007)  \n",
       "4   POINT (-73.99873112099993 40.74496920800005)  \n",
       "5   POINT (-73.83101160699994 40.86732605200007)  \n",
       "6   POINT (-73.97447511599997 40.68078561300007)  \n",
       "7   POINT (-73.84171183999997 40.88780567700008)  \n",
       "8   POINT (-73.89683284499995 40.86468367600002)  \n",
       "9  POINT (-73.87759928199995 40.754521787000044)  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5012956, 19)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find the shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARREST_KEY               0\n",
      "ARREST_DATE              0\n",
      "PD_CD                  261\n",
      "PD_DESC               9029\n",
      "KY_CD                 9029\n",
      "OFNS_DESC             9029\n",
      "LAW_CODE               196\n",
      "LAW_CAT_CD           17472\n",
      "ARREST_BORO              8\n",
      "ARREST_PRECINCT          0\n",
      "JURISDICTION_CODE       10\n",
      "AGE_GROUP               17\n",
      "PERP_SEX                 0\n",
      "PERP_RACE                0\n",
      "X_COORD_CD               1\n",
      "Y_COORD_CD               1\n",
      "Latitude                 1\n",
      "Longitude                1\n",
      "Lon_Lat                  1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "#list the number of null values present under each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5012956 entries, 0 to 5012955\n",
      "Data columns (total 19 columns):\n",
      "ARREST_KEY           int64\n",
      "ARREST_DATE          object\n",
      "PD_CD                float64\n",
      "PD_DESC              object\n",
      "KY_CD                float64\n",
      "OFNS_DESC            object\n",
      "LAW_CODE             object\n",
      "LAW_CAT_CD           object\n",
      "ARREST_BORO          object\n",
      "ARREST_PRECINCT      int64\n",
      "JURISDICTION_CODE    float64\n",
      "AGE_GROUP            object\n",
      "PERP_SEX             object\n",
      "PERP_RACE            object\n",
      "X_COORD_CD           float64\n",
      "Y_COORD_CD           float64\n",
      "Latitude             float64\n",
      "Longitude            float64\n",
      "Lon_Lat              object\n",
      "dtypes: float64(7), int64(2), object(10)\n",
      "memory usage: 726.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation and Cleaning - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the column to datetime\n",
    "df['ARREST_DATE'].dtype\n",
    "df['ARREST_DATE'] = pd.to_datetime(df['ARREST_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing values using median\n",
    "median1 = df['PD_CD'].median()\n",
    "df['PD_CD'].fillna(median1, inplace = True)\n",
    "\n",
    "median2 = df['KY_CD'].median()\n",
    "df['KY_CD'].fillna(median2, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filled NaNs normalized:\n",
      " BLACK             0.512880\n",
      "WHITE HISPANIC    0.274659\n",
      "WHITE             0.127521\n",
      "BLACK HISPANIC    0.084940\n",
      "Name: race, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BLACK             2571047\n",
       "WHITE HISPANIC    1376854\n",
       "WHITE              639256\n",
       "BLACK HISPANIC     425799\n",
       "Name: PERP_RACE, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Segregate the values based on the categories, remove the nulls and normalize the data column\n",
    "df['race'] = pd.Series(len(df['PERP_RACE']), index=df.index)\n",
    "df['race'] = 0\n",
    "\n",
    "#To assign null values\n",
    "df.loc[(df['PERP_RACE'] != 'BLACK') | \n",
    "           (df['PERP_RACE'] != 'WHITE HISPANIC') |\n",
    "           (df['PERP_RACE'] != 'WHITE') |\n",
    "           (df['PERP_RACE'] != 'BLACK HISPANIC') |\n",
    "           (df['PERP_RACE'] != 'ASIAN/PAC.ISL') |\n",
    "           (df['PERP_RACE'] != 'AMER IND') |\n",
    "           (df['PERP_RACE'].isnull() == True), 'race'] = np.nan\n",
    "\n",
    "#To assign the categorical values to the dataframe 'race'\n",
    "df.loc[(df['PERP_RACE'] == 'BLACK') | \n",
    "           (df['PERP_RACE'] == 'WHITE HISPANIC') |\n",
    "           (df['PERP_RACE'] == 'WHITE') |\n",
    "           (df['PERP_RACE'] == 'BLACK HISPANIC') |\n",
    "           (df['PERP_RACE'] == 'ASIAN/PAC.ISL') |\n",
    "           (df['PERP_RACE'] == 'AMER IND'), 'race'] = df['PERP_RACE']\n",
    "\n",
    "race_copy = df['race'].copy(deep = True)\n",
    "\n",
    "# Fill NaN values.\n",
    "df['race'].fillna(value = 1, inplace = True)\n",
    "\n",
    "# Obtain values for every race.Axis=0 for rows\n",
    "race_copy.dropna(axis = 0, inplace = True)\n",
    "sorted_race = race_copy.value_counts(normalize = True).sort_index()\n",
    "\n",
    "# Fill one values for individual person with randomly picked from random choice.\n",
    "df['race'] = df['race'].apply(lambda x: np.random.choice([x for x in sorted_race.index],\n",
    "                                replace = True, p = sorted_race) if (x == 1) else x).astype(str)\n",
    "\n",
    "#Normalize=True prints the relative frequency of the values\n",
    "print(\"\\nFilled NaNs normalized:\\n\", df['race'].value_counts(normalize = True))\n",
    "\n",
    "df['PERP_RACE'] = df['race']\n",
    "df['PERP_RACE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender proportions after filled NaNs: \n",
      " M    0.832157\n",
      "F    0.167843\n",
      "Name: sex, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M    4171564\n",
       "F     841392\n",
       "Name: PERP_SEX, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Segregate the values based on the categories, remove the nulls and normalize the data column\n",
    "df['sex'] = pd.Series(len(df['PERP_SEX']), index = df.index)\n",
    "df['sex'] = 0\n",
    "\n",
    "# Randomly stick sex to every user with NaN value.\n",
    "df.loc[(df['PERP_SEX'] != 'M') | \n",
    "           (df['PERP_SEX'] != 'F') |\n",
    "           (df['PERP_SEX'].isnull() == True), 'sex'] = np.nan\n",
    "df.loc[(df['PERP_SEX'] == 'M') | \n",
    "           (df['PERP_SEX'] == 'F'), 'sex'] = df['PERP_SEX']\n",
    "\n",
    "\n",
    "# Create a copy to calculate proportions.\n",
    "sex_copy = df['sex'].copy(deep = True)\n",
    "\n",
    "# Fill NaN values.\n",
    "df['sex'].fillna(value = 1, inplace = True)\n",
    "\n",
    "# Obtain values for every sex.\n",
    "sex_copy.dropna(axis = 0, inplace = True)\n",
    "sorted_sex = sex_copy.value_counts(normalize = True).sort_index()\n",
    "\n",
    "# Fill one values in suspector_sex_rand with randomly picked from random choice.\n",
    "df['sex'] = df['sex'].apply(lambda x: np.random.choice([x for x in sorted_sex.index],\n",
    "                                replace = True, p = sorted_sex) if (x == 1) else x).astype(str)\n",
    "print(\"Gender proportions after filled NaNs: \\n\", df['sex'].value_counts(normalize = True))\n",
    "\n",
    "df['PERP_SEX'] = df['sex']\n",
    "df['PERP_SEX'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the object type variables to string\n",
    "df['subject_sex'] = df['subject_sex'].astype(str)\n",
    "df['subject_race'] = df['subject_race'].astype(str)\n",
    "df['type'] = df['type'].astype(str)\n",
    "df['LAW_CODE'] = df['LAW_CODE'].astype(str)\n",
    "df['ARREST_BORO'] = df['ARREST_BORO'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspector age with filled NaNs normalized:\n",
      " 25-44    0.462095\n",
      "18-24    0.262886\n",
      "45-64    0.184387\n",
      "<18      0.082246\n",
      "65+      0.008386\n",
      "Name: age, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25-44    2316463\n",
       "18-24    1317836\n",
       "45-64     924324\n",
       "<18       412294\n",
       "65+        42039\n",
       "Name: AGE_GROUP, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Segregate the values based on the categories, remove the nulls and normalize the data column\n",
    "df['age'] = pd.Series(len(df['AGE_GROUP']), index = df.index)\n",
    "df['age'] = 0\n",
    "\n",
    "df.loc[(df['AGE_GROUP'] != '25-44') | \n",
    "           (df['AGE_GROUP'] != '18-24') |\n",
    "           (df['AGE_GROUP'] != '45-64') |\n",
    "           (df['AGE_GROUP'] != '65+') |\n",
    "           (df['AGE_GROUP'] != '<18') |\n",
    "           (df['AGE_GROUP'].isnull()), 'age'] = np.nan\n",
    "df.loc[(df['AGE_GROUP'] == '25-44') | \n",
    "           (df['AGE_GROUP'] == '18-24') |\n",
    "           (df['AGE_GROUP'] == '45-64') |\n",
    "           (df['AGE_GROUP'] == '65+') |\n",
    "           (df['AGE_GROUP'] == '<18'), 'age'] = df['AGE_GROUP']\n",
    "age_copy = df['age'].copy(deep = True)\n",
    "\n",
    "df['age'].fillna(value = 1, inplace = True)\n",
    "age_copy.dropna(axis = 0, inplace = True)\n",
    "sorted_age = age_copy.value_counts(normalize = True).sort_index()\n",
    "\n",
    "df['age'] = df['age'].apply(lambda x: np.random.choice([x for x in sorted_age.index],\n",
    "                               replace = True, p = sorted_age) if (x == 1) else x).astype(str)\n",
    "print(\"Suspector age with filled NaNs normalized:\\n\", df['age'].value_counts(normalize = True))\n",
    "\n",
    "df['AGE_GROUP'] = df['age']\n",
    "df['AGE_GROUP'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace null values with code=5 to state non-NYPD jurisdictions\n",
    "df['JURISDICTION_CODE'].fillna(5, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting utm\n",
      "  Using cached utm-0.6.0.tar.gz (8.6 kB)\n",
      "Building wheels for collected packages: utm\n",
      "  Building wheel for utm (setup.py): started\n",
      "  Building wheel for utm (setup.py): finished with status 'done'\n",
      "  Created wheel for utm: filename=utm-0.6.0-py3-none-any.whl size=6099 sha256=7cabdca6a54f25db34991bc15be6d87e2d6438a3abb8e9999cee3adb864540fb\n",
      "  Stored in directory: c:\\users\\swetamankala\\appdata\\local\\pip\\cache\\wheels\\70\\ab\\80\\87b7abb2752e3c3fbadc8403fda7beb387d7ac6e55cbdf3c16\n",
      "Successfully built utm\n",
      "Installing collected packages: utm\n",
      "Successfully installed utm-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install utm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Latitude'].fillna(40.821054, inplace = True) #bronx\n",
    "df['Longitude'].fillna(-73.893848, inplace = True)\n",
    "\n",
    "lat_lon = '(' + df['Longitude'].astype(str) + ', ' + df['Latitude'].astype(str) + ')'   # It`s important to apply \"(...).astype(str)\" not \"str(...)\" below - I made this mistake\n",
    "df['Lon_Lat'].fillna(value = lat_lon, axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARREST_KEY           0\n",
      "ARREST_DATE          0\n",
      "PD_CD                0\n",
      "PD_DESC              0\n",
      "KY_CD                0\n",
      "OFNS_DESC            0\n",
      "LAW_CODE             0\n",
      "LAW_CAT_CD           0\n",
      "ARREST_BORO          0\n",
      "ARREST_PRECINCT      0\n",
      "JURISDICTION_CODE    0\n",
      "AGE_GROUP            0\n",
      "PERP_SEX             0\n",
      "PERP_RACE            0\n",
      "X_COORD_CD           1\n",
      "Y_COORD_CD           1\n",
      "Latitude             0\n",
      "Longitude            0\n",
      "Lon_Lat              0\n",
      "race                 0\n",
      "sex                  0\n",
      "age                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_836b6462_1620_11eb_8e23_005056c00008row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row0_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row0_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row0_col3 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row0_col4 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row0_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row0_col6 {\n",
       "            background-color:  #4961d2;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row0_col7 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row0_col8 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col2 {\n",
       "            background-color:  #bbd1f8;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col3 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col4 {\n",
       "            background-color:  #465ecf;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col6 {\n",
       "            background-color:  #536edd;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col7 {\n",
       "            background-color:  #5470de;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row1_col8 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col1 {\n",
       "            background-color:  #bbd1f8;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col2 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col3 {\n",
       "            background-color:  #4e68d8;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col4 {\n",
       "            background-color:  #4055c8;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col6 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col7 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row2_col8 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col0 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col1 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col2 {\n",
       "            background-color:  #4b64d5;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col3 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col5 {\n",
       "            background-color:  #a2c1ff;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col6 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row3_col8 {\n",
       "            background-color:  #a2c1ff;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col0 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col1 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col2 {\n",
       "            background-color:  #4a63d3;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col3 {\n",
       "            background-color:  #455cce;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col4 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col6 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col7 {\n",
       "            background-color:  #4f69d9;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row4_col8 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col0 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col1 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col2 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col3 {\n",
       "            background-color:  #b1cbfc;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col4 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col6 {\n",
       "            background-color:  #6384eb;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col7 {\n",
       "            background-color:  #6485ec;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row5_col8 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col0 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col1 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col2 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col4 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col5 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col6 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col7 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row6_col8 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col0 {\n",
       "            background-color:  #485fd1;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col1 {\n",
       "            background-color:  #516ddb;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col2 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col4 {\n",
       "            background-color:  #445acc;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col5 {\n",
       "            background-color:  #506bda;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col6 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col7 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row7_col8 {\n",
       "            background-color:  #5572df;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col0 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col1 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col2 {\n",
       "            background-color:  #4c66d6;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col3 {\n",
       "            background-color:  #b1cbfc;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col4 {\n",
       "            background-color:  #4358cb;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col5 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col6 {\n",
       "            background-color:  #688aef;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col7 {\n",
       "            background-color:  #688aef;\n",
       "            color:  #000000;\n",
       "        }    #T_836b6462_1620_11eb_8e23_005056c00008row8_col8 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_836b6462_1620_11eb_8e23_005056c00008\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >ARREST_KEY</th>        <th class=\"col_heading level0 col1\" >PD_CD</th>        <th class=\"col_heading level0 col2\" >KY_CD</th>        <th class=\"col_heading level0 col3\" >ARREST_PRECINCT</th>        <th class=\"col_heading level0 col4\" >JURISDICTION_CODE</th>        <th class=\"col_heading level0 col5\" >X_COORD_CD</th>        <th class=\"col_heading level0 col6\" >Y_COORD_CD</th>        <th class=\"col_heading level0 col7\" >Latitude</th>        <th class=\"col_heading level0 col8\" >Longitude</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row0\" class=\"row_heading level0 row0\" >ARREST_KEY</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col1\" class=\"data row0 col1\" >-0.065639</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col2\" class=\"data row0 col2\" >-0.064885</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col3\" class=\"data row0 col3\" >0.014322</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col4\" class=\"data row0 col4\" >0.0125276</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col5\" class=\"data row0 col5\" >-0.00253095</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col6\" class=\"data row0 col6\" >-0.0181696</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col7\" class=\"data row0 col7\" >-0.0182903</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row0_col8\" class=\"data row0 col8\" >-0.00275782</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row1\" class=\"row_heading level0 row1\" >PD_CD</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col0\" class=\"data row1 col0\" >-0.065639</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col2\" class=\"data row1 col2\" >0.345509</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col3\" class=\"data row1 col3\" >0.00615705</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col4\" class=\"data row1 col4\" >0.007506</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col5\" class=\"data row1 col5\" >-0.0016599</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col6\" class=\"data row1 col6\" >0.0152557</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col7\" class=\"data row1 col7\" >0.0151866</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row1_col8\" class=\"data row1 col8\" >-0.00136975</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row2\" class=\"row_heading level0 row2\" >KY_CD</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col0\" class=\"data row2 col0\" >-0.064885</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col1\" class=\"data row2 col1\" >0.345509</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col2\" class=\"data row2 col2\" >1</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col3\" class=\"data row2 col3\" >-0.00271442</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col4\" class=\"data row2 col4\" >-0.0107495</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col5\" class=\"data row2 col5\" >-0.00203244</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col6\" class=\"data row2 col6\" >0.0103788</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col7\" class=\"data row2 col7\" >0.0103381</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row2_col8\" class=\"data row2 col8\" >-0.00184734</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row3\" class=\"row_heading level0 row3\" >ARREST_PRECINCT</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col0\" class=\"data row3 col0\" >0.014322</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col1\" class=\"data row3 col1\" >0.00615705</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col2\" class=\"data row3 col2\" >-0.00271442</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col3\" class=\"data row3 col3\" >1</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col4\" class=\"data row3 col4\" >-0.0329397</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col5\" class=\"data row3 col5\" >0.308263</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col6\" class=\"data row3 col6\" >-0.071481</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col7\" class=\"data row3 col7\" >-0.073009</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row3_col8\" class=\"data row3 col8\" >0.30815</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row4\" class=\"row_heading level0 row4\" >JURISDICTION_CODE</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col0\" class=\"data row4 col0\" >0.0125276</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col1\" class=\"data row4 col1\" >0.007506</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col2\" class=\"data row4 col2\" >-0.0107495</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col3\" class=\"data row4 col3\" >-0.0329397</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col4\" class=\"data row4 col4\" >1</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col5\" class=\"data row4 col5\" >-0.00131306</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col6\" class=\"data row4 col6\" >0.00040862</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col7\" class=\"data row4 col7\" >0.000449122</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row4_col8\" class=\"data row4 col8\" >-0.001325</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row5\" class=\"row_heading level0 row5\" >X_COORD_CD</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col0\" class=\"data row5 col0\" >-0.00253095</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col1\" class=\"data row5 col1\" >-0.0016599</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col2\" class=\"data row5 col2\" >-0.00203244</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col3\" class=\"data row5 col3\" >0.308263</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col4\" class=\"data row5 col4\" >-0.00131306</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col5\" class=\"data row5 col5\" >1</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col6\" class=\"data row5 col6\" >0.0689651</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col7\" class=\"data row5 col7\" >0.0695922</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row5_col8\" class=\"data row5 col8\" >0.99984</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row6\" class=\"row_heading level0 row6\" >Y_COORD_CD</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col0\" class=\"data row6 col0\" >-0.0181696</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col1\" class=\"data row6 col1\" >0.0152557</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col2\" class=\"data row6 col2\" >0.0103788</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col3\" class=\"data row6 col3\" >-0.071481</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col4\" class=\"data row6 col4\" >0.00040862</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col5\" class=\"data row6 col5\" >0.0689651</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col6\" class=\"data row6 col6\" >1</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col7\" class=\"data row6 col7\" >0.999964</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row6_col8\" class=\"data row6 col8\" >0.0854333</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row7\" class=\"row_heading level0 row7\" >Latitude</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col0\" class=\"data row7 col0\" >-0.0182903</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col1\" class=\"data row7 col1\" >0.0151866</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col2\" class=\"data row7 col2\" >0.0103381</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col3\" class=\"data row7 col3\" >-0.073009</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col4\" class=\"data row7 col4\" >0.000449122</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col5\" class=\"data row7 col5\" >0.0695922</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col6\" class=\"data row7 col6\" >0.999964</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col7\" class=\"data row7 col7\" >1</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row7_col8\" class=\"data row7 col8\" >0.0860372</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_836b6462_1620_11eb_8e23_005056c00008level0_row8\" class=\"row_heading level0 row8\" >Longitude</th>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col0\" class=\"data row8 col0\" >-0.00275782</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col1\" class=\"data row8 col1\" >-0.00136975</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col2\" class=\"data row8 col2\" >-0.00184734</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col3\" class=\"data row8 col3\" >0.30815</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col4\" class=\"data row8 col4\" >-0.001325</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col5\" class=\"data row8 col5\" >0.99984</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col6\" class=\"data row8 col6\" >0.0854333</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col7\" class=\"data row8 col7\" >0.0860372</td>\n",
       "                        <td id=\"T_836b6462_1620_11eb_8e23_005056c00008row8_col8\" class=\"data row8 col8\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x155aac93208>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = np.random.RandomState(0)\n",
    "#df = pd.DataFrame(rs.rand(10, 10))\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sav the dataset to perform tableau analysis\n",
    "df.to_csv(r'C:/Users/SwetaMankala/Desktop/NYPD_Arrests_Data_Clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nRowsRead = 1000\n",
    "data_clean = pd.read_csv('C:/Users/SwetaMankala/Desktop/Assignments/NYPD_Arrests_Data_Clean.csv', delimiter=',', nrows = nRowsRead, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARREST_KEY           0\n",
      "ARREST_DATE          0\n",
      "PD_CD                0\n",
      "PD_DESC              0\n",
      "KY_CD                0\n",
      "OFNS_DESC            0\n",
      "LAW_CODE             1\n",
      "LAW_CAT_CD           5\n",
      "ARREST_BORO          0\n",
      "ARREST_PRECINCT      0\n",
      "JURISDICTION_CODE    0\n",
      "AGE_GROUP            0\n",
      "PERP_SEX             0\n",
      "PERP_RACE            0\n",
      "X_COORD_CD           0\n",
      "Y_COORD_CD           0\n",
      "Latitude             0\n",
      "Longitude            0\n",
      "Lon_Lat              0\n",
      "race                 0\n",
      "sex                  0\n",
      "age                  0\n",
      "Arrest               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARREST_KEY</th>\n",
       "      <th>ARREST_DATE</th>\n",
       "      <th>PD_CD</th>\n",
       "      <th>PD_DESC</th>\n",
       "      <th>KY_CD</th>\n",
       "      <th>OFNS_DESC</th>\n",
       "      <th>LAW_CODE</th>\n",
       "      <th>LAW_CAT_CD</th>\n",
       "      <th>ARREST_BORO</th>\n",
       "      <th>ARREST_PRECINCT</th>\n",
       "      <th>...</th>\n",
       "      <th>PERP_RACE</th>\n",
       "      <th>X_COORD_CD</th>\n",
       "      <th>Y_COORD_CD</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Lon_Lat</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>Arrest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>144026181</td>\n",
       "      <td>6/26/2015</td>\n",
       "      <td>639</td>\n",
       "      <td>AGGRAVATED HARASSMENT 2</td>\n",
       "      <td>361</td>\n",
       "      <td>OFF. AGNST PUB ORD SENSBLTY &amp; RGHTS TO PRIV</td>\n",
       "      <td>PL 2403002</td>\n",
       "      <td>M</td>\n",
       "      <td>Q</td>\n",
       "      <td>102</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>1031076</td>\n",
       "      <td>193779</td>\n",
       "      <td>40.698440</td>\n",
       "      <td>-73.831130</td>\n",
       "      <td>POINT (-73.83112953899997 40.69843969400005)</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>M</td>\n",
       "      <td>45-64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>144507595</td>\n",
       "      <td>7/14/2015</td>\n",
       "      <td>969</td>\n",
       "      <td>TRAFFIC,UNCLASSIFIED INFRACTION</td>\n",
       "      <td>881</td>\n",
       "      <td>OTHER TRAFFIC INFRACTION</td>\n",
       "      <td>VTL051101A</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>984791</td>\n",
       "      <td>209846</td>\n",
       "      <td>40.742664</td>\n",
       "      <td>-73.998049</td>\n",
       "      <td>POINT (-73.99804910799998 40.74266360800004)</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>M</td>\n",
       "      <td>25-44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>144565062</td>\n",
       "      <td>7/16/2015</td>\n",
       "      <td>101</td>\n",
       "      <td>ASSAULT 3</td>\n",
       "      <td>344</td>\n",
       "      <td>ASSAULT 3 &amp; RELATED OFFENSES</td>\n",
       "      <td>PL 1200001</td>\n",
       "      <td>M</td>\n",
       "      <td>K</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>994026</td>\n",
       "      <td>195548</td>\n",
       "      <td>40.703414</td>\n",
       "      <td>-73.964743</td>\n",
       "      <td>POINT (-73.96474295699994 40.70341366900004)</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>F</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>144500188</td>\n",
       "      <td>7/14/2015</td>\n",
       "      <td>879</td>\n",
       "      <td>ADM.CODE,UNCLASSIFIED VIOLATION</td>\n",
       "      <td>675</td>\n",
       "      <td>ADMINISTRATIVE CODE</td>\n",
       "      <td>AC 010125B</td>\n",
       "      <td>V</td>\n",
       "      <td>Q</td>\n",
       "      <td>103</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>1037132</td>\n",
       "      <td>196129</td>\n",
       "      <td>40.704856</td>\n",
       "      <td>-73.809271</td>\n",
       "      <td>POINT (-73.809270971 40.70485576300007)</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>M</td>\n",
       "      <td>25-44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>144216044</td>\n",
       "      <td>7/3/2015</td>\n",
       "      <td>478</td>\n",
       "      <td>THEFT OF SERVICES, UNCLASSIFIED</td>\n",
       "      <td>343</td>\n",
       "      <td>OTHER OFFENSES RELATED TO THEFT</td>\n",
       "      <td>PL 1651503</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>984602</td>\n",
       "      <td>210686</td>\n",
       "      <td>40.744969</td>\n",
       "      <td>-73.998731</td>\n",
       "      <td>POINT (-73.99873112099993 40.74496920800005)</td>\n",
       "      <td>WHITE HISPANIC</td>\n",
       "      <td>M</td>\n",
       "      <td>18-24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ARREST_KEY ARREST_DATE  PD_CD                          PD_DESC  KY_CD  \\\n",
       "0   144026181   6/26/2015    639          AGGRAVATED HARASSMENT 2    361   \n",
       "1   144507595   7/14/2015    969  TRAFFIC,UNCLASSIFIED INFRACTION    881   \n",
       "2   144565062   7/16/2015    101                        ASSAULT 3    344   \n",
       "3   144500188   7/14/2015    879  ADM.CODE,UNCLASSIFIED VIOLATION    675   \n",
       "4   144216044    7/3/2015    478  THEFT OF SERVICES, UNCLASSIFIED    343   \n",
       "\n",
       "                                     OFNS_DESC    LAW_CODE LAW_CAT_CD  \\\n",
       "0  OFF. AGNST PUB ORD SENSBLTY & RGHTS TO PRIV  PL 2403002          M   \n",
       "1                     OTHER TRAFFIC INFRACTION  VTL051101A          M   \n",
       "2                 ASSAULT 3 & RELATED OFFENSES  PL 1200001          M   \n",
       "3                          ADMINISTRATIVE CODE  AC 010125B          V   \n",
       "4              OTHER OFFENSES RELATED TO THEFT  PL 1651503          M   \n",
       "\n",
       "  ARREST_BORO  ARREST_PRECINCT  ...       PERP_RACE X_COORD_CD Y_COORD_CD  \\\n",
       "0           Q              102  ...  WHITE HISPANIC    1031076     193779   \n",
       "1           M               10  ...  WHITE HISPANIC     984791     209846   \n",
       "2           K               90  ...  WHITE HISPANIC     994026     195548   \n",
       "3           Q              103  ...  WHITE HISPANIC    1037132     196129   \n",
       "4           M               10  ...  WHITE HISPANIC     984602     210686   \n",
       "\n",
       "    Latitude  Longitude                                       Lon_Lat  \\\n",
       "0  40.698440 -73.831130  POINT (-73.83112953899997 40.69843969400005)   \n",
       "1  40.742664 -73.998049  POINT (-73.99804910799998 40.74266360800004)   \n",
       "2  40.703414 -73.964743  POINT (-73.96474295699994 40.70341366900004)   \n",
       "3  40.704856 -73.809271       POINT (-73.809270971 40.70485576300007)   \n",
       "4  40.744969 -73.998731  POINT (-73.99873112099993 40.74496920800005)   \n",
       "\n",
       "             race  sex    age Arrest  \n",
       "0  WHITE HISPANIC    M  45-64      0  \n",
       "1  WHITE HISPANIC    M  25-44      0  \n",
       "2  WHITE HISPANIC    F  18-24      1  \n",
       "3  WHITE HISPANIC    M  25-44      1  \n",
       "4  WHITE HISPANIC    M  18-24      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spark Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import timeit                                                               \n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql.session import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local')\n",
    "\n",
    "spark = SparkSession(sc)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile('C:/Users/SwetaMankala/Desktop/Assignments/NYPD_Arrests_Data_Clean.csv')\n",
    "crime_data = file.map(lambda line: next(csv.reader(line.splitlines(), skipinitialspace=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = crime_data.first()\n",
    "data = crime_data.filter(lambda line: line != header)\n",
    "crime_df = sqlContext.createDataFrame(data, header)\n",
    "crime_df.registerTempTable(\"crime_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|LAW_CAT_CD|   CNT|\n",
      "+----------+------+\n",
      "|         M|709836|\n",
      "|         F|252717|\n",
      "|         V| 77725|\n",
      "|         I|  5342|\n",
      "|       nan|  2955|\n",
      "+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each borough, count each kind of law category (e.g. felony)\n",
    "sqlContext.sql(\"SELECT LAW_CAT_CD, COUNT(*) AS CNT FROM crime_data GROUP BY LAW_CAT_CD ORDER BY CNT desc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|ARREST_BORO|   CNT|\n",
      "+-----------+------+\n",
      "|          K|294348|\n",
      "|          M|290046|\n",
      "|          B|233175|\n",
      "|          Q|196556|\n",
      "|          S| 34449|\n",
      "|        nan|     1|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each borough, count each type of crime\n",
    "sqlContext.sql(\"SELECT DISTINCT ARREST_BORO, COUNT(*) AS CNT FROM crime_data GROUP BY ARREST_BORO ORDER BY CNT desc\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clustering crimes based on demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "latlnt = sqlContext.sql(\"SELECT ARREST_KEY,Latitude,Longitude FROM crime_data WHERE Latitude != '' AND Longitude != '' \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(latlnt.select(latlnt.Latitude,latlnt.Longitude).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def k_means():\n",
    "     start = timeit.default_timer()\n",
    "     kmeans = KMeans(n_clusters=100, random_state=0).fit(X)\n",
    "     # print(kmeans.cluster_centers_)\n",
    "     stop = timeit.default_timer()\n",
    "     print(stop - start)\n",
    "     return kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.32559910000418\n"
     ]
    }
   ],
   "source": [
    "kmeans = k_means()\n",
    "kmeans_labels = kmeans.labels_\n",
    "kmeans_cluster_centers = kmeans.cluster_centers_\n",
    "np.savetxt('kmeans_labels.out', kmeans_labels, delimiter=',')   # X is an array\n",
    "np.savetxt('kmeans_cluster_centers.out', kmeans_cluster_centers, delimiter=',')   # X is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_cluster_centers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Processing with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = round(len(data_clean)*9/10, 0)\n",
    "\n",
    "train = data_clean.loc[:cutoff]\n",
    "test = data_clean.loc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(train, test_size=0.1, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['PD_CD', 'KY_CD', 'Latitude', 'Longitude']\n",
    "text_features = ['PD_DESC', 'OFNS_DESC', 'PERP_RACE']\n",
    "model_features = numerical_features + text_features\n",
    "\n",
    "model_target = 'Arrest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SwetaMankala\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "train_data[text_features] = train_data[text_features].astype('str')\n",
    "test[text_features] = test[text_features].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning:  PD_DESC\n",
      "Text cleaning:  OFNS_DESC\n",
      "Text cleaning:  PERP_RACE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SwetaMankala\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\SwetaMankala\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Prepare cleaning functions\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stop_words = [\"a\", \"an\", \"the\", \"this\", \"that\", \"is\", \"it\", \"to\", \"and\"]\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preProcessText(text):\n",
    "    # lowercase and strip leading/trailing white space\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    \n",
    "    # remove extra white space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def lexiconProcess(text, stop_words, stemmer):\n",
    "    filtered_sentence = []\n",
    "    words = text.split(\" \")\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(stemmer.stem(w))\n",
    "    text = \" \".join(filtered_sentence)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def cleanSentence(text, stop_words, stemmer):\n",
    "    return lexiconProcess(preProcessText(text), stop_words, stemmer)\n",
    "\n",
    "# Clean the text features\n",
    "for c in text_features:\n",
    "    print('Text cleaning: ', c)\n",
    "    train[c] = [cleanSentence(item, stop_words, stemmer) for item in train[c].values]\n",
    "    test[c] = [cleanSentence(item, stop_words, stemmer) for item in test[c].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\users\\swetamankala\\anaconda3\\lib\\site-packages (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in c:\\users\\swetamankala\\anaconda3\\lib\\site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in c:\\users\\swetamankala\\anaconda3\\lib\\site-packages (from scikit-learn) (1.16.5)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\users\\swetamankala\\anaconda3\\lib\\site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in c:\\users\\swetamankala\\anaconda3\\lib\\site-packages (from scikit-learn) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('data_preprocessing',\n",
       "                 ColumnTransformer(transformers=[('numerical_pre',\n",
       "                                                  Pipeline(steps=[('num_imputer',\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  ['PD_CD', 'KY_CD', 'Latitude',\n",
       "                                                   'Longitude']),\n",
       "                                                 ('text_pre_0',\n",
       "                                                  Pipeline(steps=[('text_vect_0',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'PD_DESC'),\n",
       "                                                 ('text_pre_1',\n",
       "                                                  Pipeline(steps=[('text_vect_1',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'OFNS_DESC'),\n",
       "                                                 ('text_pre_2',\n",
       "                                                  Pipeline(steps=[('text_vect_2',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'PERP_RACE')])),\n",
       "                ('dt', RandomForestClassifier())])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "numerical_processor = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='mean'))\n",
    "#    ('num_scaler', MinMaxScaler()) # Shown in case is needed, not a must with Decision Trees\n",
    "                                ])\n",
    "# Preprocess 1st text feature\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vect_0', CountVectorizer(binary=True, max_features=50))\n",
    "                                ])\n",
    "\n",
    "# Preprocess 2nd text feature (larger vocabulary)\n",
    "text_precessor_1 = Pipeline([\n",
    "    ('text_vect_1', CountVectorizer(binary=True, max_features=50))\n",
    "                                ])\n",
    "\n",
    "# Preprocess 3rd text feature (larger vocabulary)\n",
    "text_precessor_2 = Pipeline([\n",
    "    ('text_vect_2', CountVectorizer(binary=True, max_features=50))\n",
    "                                ])\n",
    "\n",
    "data_preprocessor = ColumnTransformer([\n",
    "    ('numerical_pre', numerical_processor, numerical_features),\n",
    "    ('text_pre_0', text_processor_0, text_features[0]),\n",
    "    ('text_pre_1', text_precessor_1, text_features[1]),\n",
    "    ('text_pre_2', text_precessor_2, text_features[2])\n",
    "                                    ]) \n",
    "    \n",
    "pipeline = Pipeline([\n",
    "    ('data_preprocessing', data_preprocessor),\n",
    "    ('dt', RandomForestClassifier())\n",
    "                    ])\n",
    "    \n",
    "from sklearn import set_config\n",
    "set_config()#display='diagram')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('data_preprocessing',\n",
       "                 ColumnTransformer(transformers=[('numerical_pre',\n",
       "                                                  Pipeline(steps=[('num_imputer',\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  ['PD_CD', 'KY_CD', 'Latitude',\n",
       "                                                   'Longitude']),\n",
       "                                                 ('text_pre_0',\n",
       "                                                  Pipeline(steps=[('text_vect_0',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'PD_DESC'),\n",
       "                                                 ('text_pre_1',\n",
       "                                                  Pipeline(steps=[('text_vect_1',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'OFNS_DESC'),\n",
       "                                                 ('text_pre_2',\n",
       "                                                  Pipeline(steps=[('text_vect_2',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'PERP_RACE')])),\n",
       "                ('dt', RandomForestClassifier())])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[model_features]\n",
    "y_train = train[model_target]\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the train set:\n",
      "[[435   6]\n",
      " [  6 454]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       441\n",
      "           1       0.99      0.99      0.99       460\n",
      "\n",
      "    accuracy                           0.99       901\n",
      "   macro avg       0.99      0.99      0.99       901\n",
      "weighted avg       0.99      0.99      0.99       901\n",
      "\n",
      "Train accuracy: 0.9866814650388457\n",
      "Model performance on the validation set:\n",
      "[[42  1]\n",
      " [ 2 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97        43\n",
      "           1       0.98      0.96      0.97        48\n",
      "\n",
      "    accuracy                           0.97        91\n",
      "   macro avg       0.97      0.97      0.97        91\n",
      "weighted avg       0.97      0.97      0.97        91\n",
      "\n",
      "Validation accuracy: 0.967032967032967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Use the fitted model to make predictions on the train dataset\n",
    "# Train data going through the Pipeline it's first imputed (with means from the train), scaled (with the min/max \n",
    "#from the train data), and finally used to make predictions\n",
    "train_predictions = pipeline.predict(X_train)\n",
    "\n",
    "print('Model performance on the train set:')\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Train accuracy:\", accuracy_score(y_train, train_predictions))\n",
    "\n",
    "# Use the fitted model to make predictions on the validation dataset\n",
    "X_val = val_data[model_features]\n",
    "y_val  = val_data[model_target]\n",
    "\n",
    "val_predictions = pipeline.predict(X_val)\n",
    "\n",
    "print('Model performance on the validation set:')\n",
    "print(confusion_matrix(y_val, val_predictions))\n",
    "print(classification_report(y_val, val_predictions))\n",
    "print(\"Validation accuracy:\", accuracy_score(y_val, val_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('data_preprocessing',\n",
       "                                        ColumnTransformer(transformers=[('numerical_pre',\n",
       "                                                                         Pipeline(steps=[('num_imputer',\n",
       "                                                                                          SimpleImputer())]),\n",
       "                                                                         ['PD_CD',\n",
       "                                                                          'KY_CD',\n",
       "                                                                          'Latitude',\n",
       "                                                                          'Longitude']),\n",
       "                                                                        ('text_pre_0',\n",
       "                                                                         Pipeline(steps=[('text_vect_0',\n",
       "                                                                                          CountVectorizer(binary=True,\n",
       "                                                                                                          max_features=50))]),\n",
       "                                                                         'PD_DESC'),\n",
       "                                                                        ('text_pre_1',\n",
       "                                                                         Pipeline(steps=[('text_vect_1',\n",
       "                                                                                          CountVectorizer(binary=True,\n",
       "                                                                                                          max_features=50))]),\n",
       "                                                                         'OFNS_DESC'),\n",
       "                                                                        ('text_pre_2',\n",
       "                                                                         Pipeline(steps=[('text_vect_2',\n",
       "                                                                                          CountVectorizer(binary=True,\n",
       "                                                                                                          max_features=50))]),\n",
       "                                                                         'PERP_RACE')])),\n",
       "                                       ('dt', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'dt__max_depth': [10, 20, 30],\n",
       "                         'dt__min_samples_leaf': [1, 2, 5],\n",
       "                         'dt__min_samples_split': [10, 20, 30]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "### PIPELINE GRID_SEARCH ###\n",
    "############################\n",
    "\n",
    "# Parameter grid for GridSearch\n",
    "param_grid={'dt__max_depth': [10, 20, 30],#, 50, 75, 100, 125, 150, 200, 250], \n",
    "            'dt__min_samples_leaf': [1, 2, 5],#, 25, 30],\n",
    "            'dt__min_samples_split': [10, 20, 30]#, 25, 30, 45, 50]\n",
    "           }\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, # Base model\n",
    "                           param_grid, # Parameters to try\n",
    "                           cv = 5, # Apply 5-fold cross validation\n",
    "                           verbose = 1, # Print summary\n",
    "                           n_jobs = -1 # Use all available processors\n",
    "                          )\n",
    "\n",
    "# Fit the GridSearch to our training data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt__min_samples_split': 10, 'dt__min_samples_leaf': 1, 'dt__max_depth': 30}\n",
      "0.50719459791283\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('data_preprocessing',\n",
       "                 ColumnTransformer(transformers=[('numerical_pre',\n",
       "                                                  Pipeline(steps=[('num_imputer',\n",
       "                                                                   SimpleImputer())]),\n",
       "                                                  ['PD_CD', 'KY_CD', 'Latitude',\n",
       "                                                   'Longitude']),\n",
       "                                                 ('text_pre_0',\n",
       "                                                  Pipeline(steps=[('text_vect_0',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'PD_DESC'),\n",
       "                                                 ('text_pre_1',\n",
       "                                                  Pipeline(steps=[('text_vect_1',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'OFNS_DESC'),\n",
       "                                                 ('text_pre_2',\n",
       "                                                  Pipeline(steps=[('text_vect_2',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'PERP_RACE')])),\n",
       "                ('dt',\n",
       "                 RandomForestClassifier(max_depth=30, min_samples_split=10))])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "# Get the best model out of GridSearchCV\n",
    "classifier = grid_search.best_estimator_\n",
    "\n",
    "# Fit the best model to the train data once more\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', n_neighbors=9, p=1, weights='distance')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "all_X = train[numerical_features]\n",
    "all_y = train[model_target]\n",
    "\n",
    "# grid = GridSearchCV(knn, param_grid = hyperparameters, cv=10)\n",
    "\n",
    "best_knn = KNeighborsClassifier(n_neighbors = 9, weights='distance', algorithm='brute', p=1)\n",
    "best_knn.fit(all_X, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = best_knn.predict(train[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the train set:\n",
      "[[435   6]\n",
      " [ 13 447]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       441\n",
      "           1       0.99      0.97      0.98       460\n",
      "\n",
      "    accuracy                           0.98       901\n",
      "   macro avg       0.98      0.98      0.98       901\n",
      "weighted avg       0.98      0.98      0.98       901\n",
      "\n",
      "Train accuracy: 0.978912319644839\n"
     ]
    }
   ],
   "source": [
    "print('Model performance on the train set:')\n",
    "print(confusion_matrix(all_y, train_predictions))\n",
    "print(classification_report(all_y, train_predictions))\n",
    "print(\"Train accuracy:\", accuracy_score(all_y, train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = best_knn.predict(X_val[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the validation set:\n",
      "[[42  1]\n",
      " [ 1 47]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        43\n",
      "           1       0.98      0.98      0.98        48\n",
      "\n",
      "    accuracy                           0.98        91\n",
      "   macro avg       0.98      0.98      0.98        91\n",
      "weighted avg       0.98      0.98      0.98        91\n",
      "\n",
      "Validation accuracy: 0.978021978021978\n"
     ]
    }
   ],
   "source": [
    "print('Model performance on the validation set:')\n",
    "print(confusion_matrix(y_val, val_predictions))\n",
    "print(classification_report(y_val, val_predictions))\n",
    "print(\"Validation accuracy:\", accuracy_score(y_val, val_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
